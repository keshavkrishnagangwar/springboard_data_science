{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/mind_tree.jpg\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Mind Without Time: Classifying the Conversion to Alzheimer's Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project attempts to identify cognitively normal and persons with Mild Cognitive Impairment (MCI) who will convert to a diagnosis of Alzheimer's Disease (AD). Alzheimer's Disease is one of the most prevalent neurodegenerative disorders in North America. In Canada alone, there are 564,000 people diagnosed with dementia, a number that is expected to increase to nearly a million by 2031.Aside from the impact on an individual, dementia places a large burden on the healthcare system and persons involved with an affected individual. Dementia is currently estimated to cost 10.4 billion dollars in yearly expenses within Canada.\n",
    "\n",
    "Early diagnosis of AD is associated with a higher quality of life and a reduced cost on a healthcare system. However, detecting AD early in the disease progression is difficult due to the multifaceted nature of how neurodegeneration affects the brain, cognitive processing, and behavior. Clinical evaluation relies on assessment of a myriad of cognitive tests and biomarkers that are not always identifiable in patients with MCI, a precursor to AD. \n",
    "\n",
    "The multifaceted impact of cognitive impairment and neurodegeneration in MCI and AD suggests that machine learning algorithms may be beneficial in identifying and predicting disease progression. Current studies typically only incorporate one form of data, however, often relying solely on features extracted from structural magnetic resonance imaging (MRI) scans. Other forms of data that show promise in classification with machine learning algorithms include cognitive assessments and the connectivity patterns of resting-state functional networks. This is because spatial and episodic memory, cognitive processes that are typically the first affected in MCI and AD, rely on complex, dynamic interactions of distributed neural networks and are therefore susceptible to the impact of neurodegeneration. Critically, there has yet to be an assessment of how machine learning algorithms perform using features extracted from structural and functional MRI data, as well as cognitive assessments. This project aims to remedy this.\n",
    "\n",
    "**Target audience and use cases:**\n",
    "\n",
    "Healthcare providers. Structural and resting-state functional MRIs are one of easiest and fastest methods of brain imaging. Using them to classify persons at risk of AD would assist in providing targeted treatments.\n",
    "\n",
    "**Notebook overview**\n",
    "\n",
    "This notebook explores different machine learning approaches to classifying persons at risk of AD onset. It also covers model optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building a core model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first goal is to build a classification model that will classify individuals who convert from those that do not. We will use a reduced feature set in order to maximize the amount of datapoints being classified. These features will be based on demographic information, cognitive assessments, genetic, and structural MRI data as they are the variables that are recorded for the majority of the patients. Later, we will build reduced models that include other feature types and evaluate how they perform relative to our core model.\n",
    "\n",
    "For our intial model, we will look at predicting AD onset just from the values at baseline. The reason is that this will provide the maximum time on average to target patients who will convert with early interventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidenarnold/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/aidenarnold/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "/Users/aidenarnold/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/aidenarnold/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "from fastai import *          # Quick accesss to most common functionality\n",
    "from fastai.tabular import *  # Quick accesss to tabular functionality\n",
    "\n",
    "\n",
    "# remove future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(module='sklearn*', action='ignore', category=DeprecationWarning)\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# set figure properties\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_final.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rid', 'viscode', 'd1', 'd2', 'dx_bl', 'dxchange', 'age', 'ptgender',\n",
       "       'pteducat', 'ptethcat', 'ptmarry', 'cdrsb_bl', 'cdrsb', 'adas13_bl',\n",
       "       'adas13', 'mmse_bl', 'mmse', 'moca', 'ecogptmem', 'ecogptvisspat',\n",
       "       'ventricles_bl', 'wholebrain_bl', 'icv_bl', 'l_hippocampus_l',\n",
       "       'l_hippocampus_r', 'x_hippocampus_l', 'x_hippocampus_r',\n",
       "       'l_entorhinal_l', 'l_entorhinal_r', 'l_entorhinal_l_thick',\n",
       "       'l_entorhinal_r_thick', 'x_entorhinal_l', 'x_entorhinal_r',\n",
       "       'x_entorhinal_l_thick', 'x_entorhinal_r_thick', 'fdg', 'fdg_bl', 'pib',\n",
       "       'av45', 'av45_bl', 'md_hippocampus_r', 'apoe4', 'converted', 'diff_1',\n",
       "       'diff_2', 'x_hippocampus_l_bl', 'x_hippocampus_r_bl',\n",
       "       'x_entorhinal_l_bl', 'x_entorhinal_r_bl', 'x_entorhinal_l_thick_bl',\n",
       "       'x_entorhinal_r_thick_bl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop patients with baseline conversion to AD\n",
    "df = df.loc[df.dx_bl != 'AD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract non converter datapoints\n",
    "df_non = df.loc[df.converted==0]\n",
    "# extract all converter datapoints\n",
    "df_converted = df.loc[df.converted==1]\n",
    "# concatenate\n",
    "df_core = pd.concat([df_non, df_converted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_core['converted'] = df_core['converted'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9027, 51)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_core.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6677\n",
       "1    2350\n",
       "Name: converted, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_core.converted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rid', 'viscode', 'd1', 'd2', 'dx_bl', 'dxchange', 'age', 'ptgender',\n",
       "       'pteducat', 'ptethcat', 'ptmarry', 'cdrsb_bl', 'cdrsb', 'adas13_bl',\n",
       "       'adas13', 'mmse_bl', 'mmse', 'moca', 'ecogptmem', 'ecogptvisspat',\n",
       "       'ventricles_bl', 'wholebrain_bl', 'icv_bl', 'l_hippocampus_l',\n",
       "       'l_hippocampus_r', 'x_hippocampus_l', 'x_hippocampus_r',\n",
       "       'l_entorhinal_l', 'l_entorhinal_r', 'l_entorhinal_l_thick',\n",
       "       'l_entorhinal_r_thick', 'x_entorhinal_l', 'x_entorhinal_r',\n",
       "       'x_entorhinal_l_thick', 'x_entorhinal_r_thick', 'fdg', 'fdg_bl', 'pib',\n",
       "       'av45', 'av45_bl', 'md_hippocampus_r', 'apoe4', 'converted', 'diff_1',\n",
       "       'diff_2', 'x_hippocampus_l_bl', 'x_hippocampus_r_bl',\n",
       "       'x_entorhinal_l_bl', 'x_entorhinal_r_bl', 'x_entorhinal_l_thick_bl',\n",
       "       'x_entorhinal_r_thick_bl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_core.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rid</th>\n",
       "      <th>viscode</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>dx_bl</th>\n",
       "      <th>dxchange</th>\n",
       "      <th>age</th>\n",
       "      <th>ptgender</th>\n",
       "      <th>pteducat</th>\n",
       "      <th>ptethcat</th>\n",
       "      <th>...</th>\n",
       "      <th>apoe4</th>\n",
       "      <th>converted</th>\n",
       "      <th>diff_1</th>\n",
       "      <th>diff_2</th>\n",
       "      <th>x_hippocampus_l_bl</th>\n",
       "      <th>x_hippocampus_r_bl</th>\n",
       "      <th>x_entorhinal_l_bl</th>\n",
       "      <th>x_entorhinal_r_bl</th>\n",
       "      <th>x_entorhinal_l_thick_bl</th>\n",
       "      <th>x_entorhinal_r_thick_bl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>16</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4117.0</td>\n",
       "      <td>4219.0</td>\n",
       "      <td>2241.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>3.254</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>16</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4117.0</td>\n",
       "      <td>4219.0</td>\n",
       "      <td>2241.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>3.254</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>16</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4117.0</td>\n",
       "      <td>4219.0</td>\n",
       "      <td>2241.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>3.254</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>16</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4117.0</td>\n",
       "      <td>4219.0</td>\n",
       "      <td>2241.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>3.254</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.3</td>\n",
       "      <td>Male</td>\n",
       "      <td>16</td>\n",
       "      <td>Not Hisp/Latino</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4117.0</td>\n",
       "      <td>4219.0</td>\n",
       "      <td>2241.0</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>3.254</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rid  viscode  d1  d2 dx_bl  dxchange   age ptgender  pteducat  \\\n",
       "0    2        0   1   1    CN       1.0  74.3     Male        16   \n",
       "1    2        6   1   1    CN       1.0  74.3     Male        16   \n",
       "2    2       36   1   1    CN       1.0  74.3     Male        16   \n",
       "3    2       60   1   1    CN       1.0  74.3     Male        16   \n",
       "4    2       72   1   1    CN       1.0  74.3     Male        16   \n",
       "\n",
       "          ptethcat           ...            apoe4  converted  diff_1  diff_2  \\\n",
       "0  Not Hisp/Latino           ...              0.0          0  -18.67     NaN   \n",
       "1  Not Hisp/Latino           ...              0.0          0  -18.67     NaN   \n",
       "2  Not Hisp/Latino           ...              0.0          0  -18.67     NaN   \n",
       "3  Not Hisp/Latino           ...              0.0          0  -18.67     NaN   \n",
       "4  Not Hisp/Latino           ...              0.0          0  -18.67     NaN   \n",
       "\n",
       "   x_hippocampus_l_bl  x_hippocampus_r_bl  x_entorhinal_l_bl  \\\n",
       "0              4117.0              4219.0             2241.0   \n",
       "1              4117.0              4219.0             2241.0   \n",
       "2              4117.0              4219.0             2241.0   \n",
       "3              4117.0              4219.0             2241.0   \n",
       "4              4117.0              4219.0             2241.0   \n",
       "\n",
       "   x_entorhinal_r_bl  x_entorhinal_l_thick_bl  x_entorhinal_r_thick_bl  \n",
       "0             1936.0                    3.254                     3.61  \n",
       "1             1936.0                    3.254                     3.61  \n",
       "2             1936.0                    3.254                     3.61  \n",
       "3             1936.0                    3.254                     3.61  \n",
       "4             1936.0                    3.254                     3.61  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_core.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(fitted_model, scaled=True, cv=False):\n",
    "    \"\"\"This method is used to evaluate model performance. It takes a fitted classification model and\n",
    "    generates an accuracy score and plots an ROC curve.\"\"\"\n",
    "\n",
    "    # set training/test sets\n",
    "    if scaled:\n",
    "        X_train_set = X_train_trans\n",
    "        X_test_set = X_test_trans\n",
    "    else:\n",
    "        X_train_set = X_train\n",
    "        X_test_set = X_test\n",
    "\n",
    "    # calculate predicted probabilities\n",
    "    y_pred_prob = fitted_model.predict_proba(X_test_set)[:,1]\n",
    "\n",
    "    # Generate ROC curve values: fpr, tpr, thresholds\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "    \n",
    "    # generate precision-recall values\n",
    "    precision, recall, pr_thresholds = precision_recall_curve(y_test, fitted_model.predict(X_test_set))\n",
    "    # calculate average precision\n",
    "    average_precision = average_precision_score(y_test, fitted_model.predict(X_test_set))\n",
    "    \n",
    "    # figure settings\n",
    "    f, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "\n",
    "    # plot ROC curve\n",
    "    ax1.plot([0, 1], [0, 1], 'k--')\n",
    "    ax1.plot(fpr, tpr)\n",
    "    ax1.set_xlabel('False Positive Rate')\n",
    "    ax1.set_ylabel('True Positive Rate')\n",
    "    ax1.set_title('ROC Curve')\n",
    "    \n",
    "    # plot precision-recall curve\n",
    "    ax2.step(precision, recall, where='post')\n",
    "    ax2.set_xlabel('Recall')\n",
    "    ax2.set_ylabel('Precision')\n",
    "    ax2.set_title('Precion-Recall Curve')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    # display results\n",
    "    print(f'Accuracy on the training data is {round(accuracy_score(y_train, fitted_model.predict(X_train_set)), 3)}.')\n",
    "\n",
    "    # display model accuracy\n",
    "    print(f'Accuracy on the test data is {round(accuracy_score(y_test, fitted_model.predict(X_test_set)), 3)}.')\n",
    "\n",
    "    # display AUC score\n",
    "    print(f'The model AUC for ROC curve of the test data is {round(roc_auc_score(y_test, y_pred_prob), 3)}')\n",
    "    \n",
    "    # display average precision\n",
    "    print(f'Average precision is {round(average_precision, 3)}.')\n",
    "\n",
    "    if cv:\n",
    "        print(f'The best parameters are {fitted_model.best_params_}.')\n",
    "\n",
    "\n",
    "def model_performance(classifier, scaled=True, cv=False):\n",
    "    \"\"\"This method fits and evaluates a model. Input parameter is classifier type.\n",
    "    Scaled indicates whether to use a scaled train/test set. Cv indicates whether evaluating cross validation performance.\"\"\"\n",
    "\n",
    "    # set training data\n",
    "    if scaled:\n",
    "        X_train_set = X_train_trans\n",
    "    else:\n",
    "        X_train_set = X_train\n",
    "\n",
    "    # initiate classifier\n",
    "    clf = classifier\n",
    "    # fit model\n",
    "    clf = clf.fit(X_train_trans, y_train)\n",
    "    # evaluate model\n",
    "    model_eval(fitted_model=clf, scaled=scaled, cv=cv)\n",
    "    # return fitted model\n",
    "    return clf\n",
    "\n",
    "def nested_split(split_on, dataframe, test_prop):\n",
    "    \"\"\"This methods extracts a proportion of observations for each patient for train/test splits.\n",
    "    Returns a list of index values that ensure stratification based on number of patients.\"\"\"\n",
    "    npr.seed = 42\n",
    "    # find number of label classes\n",
    "    n_classes = dataframe[split_on].unique()\n",
    "    # list of test indicies for each class\n",
    "    test_non = []\n",
    "    test_conv = []\n",
    "    for n in n_classes:\n",
    "        # list of patient IDs\n",
    "        patients = dataframe[dataframe[split_on] == n].rid.unique()\n",
    "        # number of required samples for the test set\n",
    "        n_samples = len(dataframe[dataframe[split_on] == n]) * test_prop\n",
    "        # proportion per patient rounded down\n",
    "        proportion = round(n_samples / len(patients) - 0.5)\n",
    "        # remainder to randomly sample from\n",
    "        remainder = round((n_samples - proportion * len(patients)) - 0.5)\n",
    "        p_to_resample = [i for i in patients if len(dataframe[dataframe.rid == i]) > 1]\n",
    "        # create list of patient IDs to resample based on remainder\n",
    "        resample = np.random.choice(p_to_resample, remainder, replace=False)\n",
    "        # randomly pick indices for each patient\n",
    "        for p in patients:\n",
    "            if p in resample:\n",
    "                sample = proportion + 1\n",
    "            else:\n",
    "                sample = proportion\n",
    "            if n == 0:\n",
    "                test_non = test_non + np.random.choice(dataframe[dataframe.rid==p].index, sample, replace=False).tolist()\n",
    "            else:\n",
    "                test_conv = test_conv + np.random.choice(dataframe[dataframe.rid==p].index, sample, replace=False).tolist()\n",
    "    return test_non+test_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices for test set\n",
    "test_ind = nested_split('converted', df, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1805"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices for training set\n",
    "train_ind = [i for i in df_core.index if i not in test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7222"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['d1', 'd2', 'dxchange', 'rid', 'viscode','cdrsb_bl', 'ptethcat',\n",
    " 'adas13_bl',\n",
    " 'mmse_bl',\n",
    " 'ventricles_bl',\n",
    " 'wholebrain_bl',\n",
    " 'icv_bl',\n",
    " 'fdg_bl',\n",
    " 'av45_bl',\n",
    " 'x_hippocampus_l_bl',\n",
    " 'x_hippocampus_r_bl',\n",
    " 'x_entorhinal_l_bl',\n",
    " 'x_entorhinal_r_bl',\n",
    " 'x_entorhinal_l_thick_bl',\n",
    " 'x_entorhinal_r_thick_bl']\n",
    "train_df = df_core.loc[train_ind, :].drop(cols_to_drop, axis=1)\n",
    "test_df = df_core.loc[test_ind, :].drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'converted'\n",
    "cat_names = ['ptgender', 'ptmarry', 'dx_bl', 'apoe4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nn = pd.concat([train_df, test_df])\n",
    "df_nn.to_csv('df_nn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7222 entries, 0 to 10100\n",
      "Data columns (total 54 columns):\n",
      "dx_bl                      7222 non-null category\n",
      "age                        7222 non-null float64\n",
      "ptgender                   7222 non-null category\n",
      "pteducat                   7222 non-null int64\n",
      "ptmarry                    7222 non-null category\n",
      "cdrsb                      7222 non-null float64\n",
      "adas13                     7222 non-null float64\n",
      "mmse                       7222 non-null float64\n",
      "moca                       7222 non-null float64\n",
      "ecogptmem                  7222 non-null float64\n",
      "ecogptvisspat              7222 non-null float64\n",
      "l_hippocampus_l            7222 non-null float64\n",
      "l_hippocampus_r            7222 non-null float64\n",
      "x_hippocampus_l            7222 non-null float64\n",
      "x_hippocampus_r            7222 non-null float64\n",
      "l_entorhinal_l             7222 non-null float64\n",
      "l_entorhinal_r             7222 non-null float64\n",
      "l_entorhinal_l_thick       7222 non-null float64\n",
      "l_entorhinal_r_thick       7222 non-null float64\n",
      "x_entorhinal_l             7222 non-null float64\n",
      "x_entorhinal_r             7222 non-null float64\n",
      "x_entorhinal_l_thick       7222 non-null float64\n",
      "x_entorhinal_r_thick       7222 non-null float64\n",
      "fdg                        7222 non-null float64\n",
      "pib                        7222 non-null float64\n",
      "av45                       7222 non-null float64\n",
      "md_hippocampus_r           7222 non-null float64\n",
      "apoe4                      7222 non-null category\n",
      "converted                  7222 non-null int64\n",
      "diff_1                     7222 non-null float64\n",
      "diff_2                     7222 non-null float64\n",
      "l_entorhinal_l_thick_na    7222 non-null bool\n",
      "ecogptvisspat_na           7222 non-null bool\n",
      "fdg_na                     7222 non-null bool\n",
      "x_entorhinal_r_na          7222 non-null bool\n",
      "pib_na                     7222 non-null bool\n",
      "l_hippocampus_l_na         7222 non-null bool\n",
      "mmse_na                    7222 non-null bool\n",
      "l_entorhinal_r_na          7222 non-null bool\n",
      "l_entorhinal_r_thick_na    7222 non-null bool\n",
      "x_hippocampus_r_na         7222 non-null bool\n",
      "cdrsb_na                   7222 non-null bool\n",
      "x_entorhinal_l_thick_na    7222 non-null bool\n",
      "x_entorhinal_l_na          7222 non-null bool\n",
      "adas13_na                  7222 non-null bool\n",
      "md_hippocampus_r_na        7222 non-null bool\n",
      "l_hippocampus_r_na         7222 non-null bool\n",
      "x_entorhinal_r_thick_na    7222 non-null bool\n",
      "x_hippocampus_l_na         7222 non-null bool\n",
      "diff_2_na                  7222 non-null bool\n",
      "av45_na                    7222 non-null bool\n",
      "moca_na                    7222 non-null bool\n",
      "ecogptmem_na               7222 non-null bool\n",
      "l_entorhinal_l_na          7222 non-null bool\n",
      "dtypes: bool(23), category(4), float64(25), int64(2)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .cat accessor with a 'category' dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c18ea974f7b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularDataBunch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdep_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCategorify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFillMissing\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Life/data_science/fastai/fastai/tabular/data.py\u001b[0m in \u001b[0;36mfrom_df\u001b[0;34m(cls, path, train_df, valid_df, dep_var, test_df, tfms, cat_names, cont_names, stats, log_output, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mcat_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mcont_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcont_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdep_var\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdep_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         valid_ds = TabularDataset.from_dataframe(valid_df, dep_var, train_ds.tfms, train_ds.cat_names,\n\u001b[1;32m     80\u001b[0m                                              train_ds.cont_names, train_ds.stats, log_output)\n",
      "\u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Life/data_science/fastai/fastai/tabular/data.py\u001b[0m in \u001b[0;36mfrom_dataframe\u001b[0;34m(cls, df, dep_var, tfms, cat_names, cont_names, stats, log_output)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mtfms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mcat_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcont_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdep_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtfms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcont_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcat_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcont_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Life/data_science/fastai/fastai/tabular/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, dep_var, cat_names, cont_names, stats, log_output)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcat_names\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Life/data_science/fastai/fastai/tabular/data.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcat_names\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4370\u001b[0m         if (name in self._internal_names_set or name in self._metadata or\n\u001b[1;32m   4371\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 4372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4373\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m# http://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2377\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2378\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2379\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2386\u001b[0;31m             raise AttributeError(\"Can only use .cat accessor with a \"\n\u001b[0m\u001b[1;32m   2387\u001b[0m                                  \"'category' dtype\")\n\u001b[1;32m   2388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .cat accessor with a 'category' dtype"
     ]
    }
   ],
   "source": [
    "data = TabularDataBunch.from_df('nn', train_df, test_df, dep_var, tfms=[Categorify, FillMissing], cat_names=cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
